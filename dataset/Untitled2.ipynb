{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7e0936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\mika\\anaconda3\\lib\\site-packages (0.10.0.post2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from librosa) (1.23.5)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from librosa) (1.10.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from librosa) (0.3.5)\n",
      "Requirement already satisfied: pooch<1.7,>=1.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from librosa) (1.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from librosa) (0.56.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from librosa) (1.2.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mika\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (65.6.3)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
      "Requirement already satisfied: appdirs in c:\\users\\mika\\anaconda3\\lib\\site-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: requests in c:\\users\\mika\\anaconda3\\lib\\site-packages (from pooch<1.7,>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\mika\\anaconda3\\lib\\site-packages (from pooch<1.7,>=1.0->librosa) (22.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mika\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from requests->pooch<1.7,>=1.0->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from requests->pooch<1.7,>=1.0->librosa) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from requests->pooch<1.7,>=1.0->librosa) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from requests->pooch<1.7,>=1.0->librosa) (1.26.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2679a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\mika\\anaconda3\\lib\\site-packages (2.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd481d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\mika\\anaconda3\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd919df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\mika\\anaconda3\\lib\\site-packages (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855be253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\mika\\anaconda3\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edf01f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\mika\\anaconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.56.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mika\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04c70a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.layers import MaxPooling2D, Conv2D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66684af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows(data, window_size):\n",
    "  start = 0\n",
    "  while start < len(data):\n",
    "    yield start, start + window_size\n",
    "    start += (window_size // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "854b4de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n"
     ]
    }
   ],
   "source": [
    "def extract_features(sub_dirs, file_ext=\"*.wav\"):\n",
    "  window_size = hop_length * (frames - 1)\n",
    "  log_specgrams = []\n",
    "  labels = []\n",
    "  for l, sub_dir in enumerate(sub_dirs):\n",
    "    for fn in glob.glob(os.path.join(file_url, sub_dir, file_ext)):\n",
    "      sound_clip, _ = librosa.load(fn, sr=sample_rate)\n",
    "      print('Extracting features from: ' + fn)\n",
    "      label = fn.split('\\\\')[-2]\n",
    "      for (start, end) in windows(sound_clip, window_size):\n",
    "        if (len(sound_clip[start:end]) == window_size):\n",
    "          signal = sound_clip[start:end]\n",
    "          melspec = librosa.feature.melspectrogram(signal, n_mels=bands, sr=sample_rate, n_fft=n_fft, hop_length=hop_length)\n",
    "          logspec = librosa.power_to_db(melspec, ref=np.max)\n",
    "          logspec = logspec / 80 + 1\n",
    "          logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "          log_specgrams.append(logspec)\n",
    "          labels.append(label)\n",
    "  features = np.asarray(log_specgrams).reshape(len(log_specgrams), bands, frames, 1)\n",
    "  np_labels = np.array(labels, dtype=np.int)\n",
    "  unique, counts = np.unique(np_labels, return_counts=True) # to check the number of samples for each class\n",
    "\n",
    "  return np.array(features), np_labels\n",
    "print(\"hola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e79030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "  tr_sub_dirs = [\"0\", \"1\"]\n",
    "  tr_features, tr_labels = extract_features(tr_sub_dirs)\n",
    "  np.savez(file_url, tr_features, tr_labels)\n",
    "  return tr_features, tr_labels\n",
    "  # Comment the above code and use the code below to not process the files again\n",
    "  npread = np.load(file_url + '.npz')\n",
    "  return npread['arr_0'], npread['arr_1']\n",
    "print(\"Hola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2dfb539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(bands, frames, 1)))\n",
    "  model.add(MaxPooling2D((2, 2)))\n",
    "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(MaxPooling2D((2, 2)))\n",
    "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(256, activation='relu'))\n",
    "  model.add(Dense(2, activation='sigmoid'))\n",
    "  model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])\n",
    "  model.summary()\n",
    "  \n",
    "  return model\n",
    "print(\"hola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "04bf30f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_model(model, xtrain, ytrain, xval, yval):\n",
    "  model.fit(xtrain, ytrain,  batch_size=32, epochs=10, verbose=2)\n",
    "  y_predicted_classes = model.predict_classes(xval)\n",
    "  y_predicted_probability = model.predict(xval)\n",
    "  conf_matrix = skm.confusion_matrix(yval, y_predicted_classes, labels=[1, 0])\n",
    "  print(\"Confusion matrix: \\n\"  + str(conf_matrix))\n",
    "  score = model.evaluate(xval, yval, verbose=0)\n",
    "  print(\"Accuracy: %.2f%%\" % ( score[1] * 100))\n",
    "  precision = skm.precision_score(yval, y_predicted_classes, pos_label=0)\n",
    "  print(\"Precision: %.2f%%\" % (precision*100))\n",
    "  recall = skm.recall_score(yval, y_predicted_classes, pos_label=0)\n",
    "  print(\"Recall: %.2f%%\" % (recall*100))\n",
    "  f1_score = skm.f1_score(yval, y_predicted_classes, pos_label=0)\n",
    "  print(\"F1-score: %.4f\" % f1_score)\n",
    "  auroc = skm.roc_auc_score(yval, y_predicted_classes)\n",
    "  print(\"AUROC: %.4f\" % auroc)\n",
    "\n",
    "  return score[1], precision, recall, f1_score\n",
    "print(\"hola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "32cf7dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)  # for reproducibility\n",
    "\n",
    "bands = 60\n",
    "frames = 40\n",
    "hop_length = 256\n",
    "n_fft = 1024\n",
    "\n",
    "sample_rate = 8000\n",
    "\n",
    "n_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0437082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mika\\AppData\\Local\\Temp\\ipykernel_2092\\2843618997.py:20: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np_labels = np.array(labels, dtype=np.int)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m recall_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m f1_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (train, test) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mskf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m     11\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Fold\u001b[39m\u001b[38;5;124m\"\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_folds)\n\u001b[0;32m     12\u001b[0m   model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# Clearing the NN.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:771\u001b[0m, in \u001b[0;36mStratifiedKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;124;03m    to an integer.\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 771\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 931\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    932\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    938\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "X, Y = load_data()\n",
    "\n",
    "skf = StratifiedKFold(n_splits = n_folds, shuffle = True)\n",
    "\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for i, (train, test) in enumerate(skf.split(X, Y)):\n",
    "  print(\"Running Fold\", i + 1, \"/\", n_folds)\n",
    "  model = None # Clearing the NN.\n",
    "  model = create_model()\n",
    "\n",
    "  # Generate batches from indices\n",
    "  xtrain, xval = X[train], X[test]\n",
    "  ytrain, yval = Y[train], Y[test]\n",
    "  accuracy, precision, recall, f1 = train_and_evaluate_model(model, xtrain, ytrain, xval, yval)\n",
    "  accuracy_scores.append(accuracy)\n",
    "  precision_scores.append(precision)\n",
    "  recall_scores.append(recall)\n",
    "  f1_scores.append(f1)\n",
    "\n",
    "print(\"Accuracy scores: \" + str(accuracy_scores))\n",
    "print(\"Precision scores: \" + str(precision_scores))\n",
    "print(\"Recall scores: \" + str(recall_scores))\n",
    "print(\"F1 scores: \" + str(f1_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f5445f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = 'C:\\\\Users\\\\Mika\\\\Documents\\\\GitHub\\\\Proyecto\\\\dataset.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8fb47eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mika\\AppData\\Local\\Temp\\ipykernel_2092\\3819417076.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np_labels = np.array(labels, dtype=np.int)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 100\u001b[0m\n\u001b[0;32m     96\u001b[0m recall_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     97\u001b[0m f1_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (dataset, test) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mskf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    101\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Fold\u001b[39m\u001b[38;5;124m\"\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_folds)\n\u001b[0;32m    102\u001b[0m   model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# Clearing the NN.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:771\u001b[0m, in \u001b[0;36mStratifiedKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;124;03m    to an integer.\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 771\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 931\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    932\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    938\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "file_url = 'C:\\\\Users\\\\Mika\\\\Documents\\\\GitHub\\\\Proyecto\\\\dataset'\n",
    "def windows(data, window_size):\n",
    "  start = 0\n",
    "  while start < len(data):\n",
    "    yield start, start + window_size\n",
    "    start += (window_size // 2)\n",
    "\n",
    "def extract_features( sub_dirs, file_ext=\"*.wav\"):\n",
    "  window_size = hop_length * (frames - 1)\n",
    "  log_specgrams = []\n",
    "  labels = []\n",
    "  for l, sub_dir in enumerate(sub_dirs):\n",
    "    for fn in glob.glob(os.path.join(file_url, sub_dir, file_ext)):\n",
    "      sound_clip, _ = librosa.load(fn, sr=sample_rate)\n",
    "      print('Extracting features from: ' + fn)\n",
    "      label = fn.split('\\\\')[-2]\n",
    "      for (start, end) in windows(sound_clip, window_size):\n",
    "        if (len(sound_clip[start:end]) == window_size):\n",
    "          signal = sound_clip[start:end]\n",
    "          melspec = librosa.feature.melspectrogram(signal, n_mels=bands, sr=sample_rate, n_fft=n_fft, hop_length=hop_length)\n",
    "          logspec = librosa.power_to_db(melspec, ref=np.max)\n",
    "          logspec = logspec / 80 + 1\n",
    "          logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "          log_specgrams.append(logspec)\n",
    "          labels.append(label)\n",
    "  features = np.asarray(log_specgrams).reshape(len(log_specgrams), bands, frames, 1)\n",
    "  np_labels = np.array(labels, dtype=np.int)\n",
    "  unique, counts = np.unique(np_labels, return_counts=True) # to check the number of samples for each class\n",
    "\n",
    "  return np.array(features), np_labels\n",
    "\n",
    "def load_data():\n",
    "  tr_sub_dirs = [\"0\", \"1\"]\n",
    "  tr_features, tr_labels = extract_features(tr_sub_dirs)\n",
    "  np.savez(file_url, tr_features, tr_labels)\n",
    "  return tr_features, tr_labels\n",
    "  # Comment the above code and use the code below to not process the files again\n",
    "  npread = np.load(file_url + '.npz')\n",
    "  return npread['arr_0'], npread['arr_1']\n",
    "\n",
    "def create_model():\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(bands, frames, 1)))\n",
    "  model.add(MaxPooling2D((2, 2)))\n",
    "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(MaxPooling2D((2, 2)))\n",
    "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(256, activation='relu'))\n",
    "  model.add(Dense(2, activation='sigmoid'))\n",
    "  model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])\n",
    "  model.summary()\n",
    "  \n",
    "  return model\n",
    "\n",
    "def train_and_evaluate_model(model, xtrain, ytrain, xval, yval):\n",
    "  model.fit(xtrain, ytrain,  batch_size=32, epochs=10, verbose=2)\n",
    "  y_predicted_classes = model.predict_classes(xval)\n",
    "  y_predicted_probability = model.predict(xval)\n",
    "  conf_matrix = skm.confusion_matrix(yval, y_predicted_classes, labels=[1, 0])\n",
    "  print(\"Confusion matrix: \\n\"  + str(conf_matrix))\n",
    "  score = model.evaluate(xval, yval, verbose=0)\n",
    "  print(\"Accuracy: %.2f%%\" % ( score[1] * 100))\n",
    "  precision = skm.precision_score(yval, y_predicted_classes, pos_label=0)\n",
    "  print(\"Precision: %.2f%%\" % (precision*100))\n",
    "  recall = skm.recall_score(yval, y_predicted_classes, pos_label=0)\n",
    "  print(\"Recall: %.2f%%\" % (recall*100))\n",
    "  f1_score = skm.f1_score(yval, y_predicted_classes, pos_label=0)\n",
    "  print(\"F1-score: %.4f\" % f1_score)\n",
    "  auroc = skm.roc_auc_score(yval, y_predicted_classes)\n",
    "  print(\"AUROC: %.4f\" % auroc)\n",
    "\n",
    "  return score[1], precision, recall, f1_score\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)  # for reproducibility\n",
    "\n",
    "#file_url = 'E:\\\\mosquitos\\\\train'\n",
    "\n",
    "bands = 60\n",
    "frames = 40\n",
    "hop_length = 256\n",
    "n_fft = 1024\n",
    "\n",
    "sample_rate = 8000\n",
    "\n",
    "n_folds = 10\n",
    "X, Y = load_data()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "\n",
    "for i, (dataset, test) in enumerate(skf.split(X, Y)):\n",
    "  print(\"Running Fold\", i + 1, \"/\", n_folds)\n",
    "  model = None # Clearing the NN.\n",
    "  model = create_model()\n",
    "\n",
    "  # Generate batches from indices\n",
    "  xtrain, xval = X[dataset], X[test]\n",
    "  ytrain, yval = Y[dataset], Y[test]\n",
    "  accuracy, precision, recall, f1 = train_and_evaluate_model(model, xtrain, ytrain, xval, yval)\n",
    "  accuracy_scores.append(accuracy)\n",
    "  precision_scores.append(precision)\n",
    "  recall_scores.append(recall)\n",
    "  f1_scores.append(f1)\n",
    "\n",
    "print(\"Accuracy scores: \" + str(accuracy_scores))\n",
    "print(\"Precision scores: \" + str(precision_scores))\n",
    "print(\"Recall scores: \" + str(recall_scores))\n",
    "print(\"F1 scores: \" + str(f1_scores))\n",
    "\n",
    "csv_filename = \"binary.csv\"\n",
    "\n",
    "with open(csv_filename, 'w', newline='') as csv_file:\n",
    "  csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "  csv_writer.writerow(['accuracy', 'precision', 'recall', 'f1_score'])\n",
    "\n",
    "  for i in range(len(accuracy_scores)):\n",
    "    csv_writer.writerow([accuracy_scores[i], precision_scores[i], recall_scores[i], f1_scores[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6804d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
